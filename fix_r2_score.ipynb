{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n",
      "3 0\n"
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "args = Args(exp_version=\"3.0\", test=True, batch_size=4)\n",
    "\n",
    "\n",
    "config = exp_configs.get_experiment_config(\n",
    "        args.exp_version,\n",
    "        local=args.test,\n",
    "        vm_name=args.vm_name,\n",
    "        batch_size=args.batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from scratch.\n",
      "Using Dummy Data\n",
      "\n",
      "ClimSimulator\n",
      "-------------------------\n",
      "inputs(x)                      = bf16[4 490]           \n",
      "expand_dims(x)                 = bf16[4 490 1]         \n",
      "concat_x_learn(x)              = f32[4 490 128]        \n",
      "concat_y_learn(x)              = f32[4 798 128]        \n",
      "pos_emb(x)                     = f32[4 798 128]        \n",
      "Inside SelfAttention\n",
      " ....  ....  ....  .... \n",
      "inputs(x)                      = f32[4 798 128]        \n",
      "linear(x)                      = f32[4 798 384]        \n",
      "split(q)                       = f32[4 798 2 64]       \n",
      "split(k)                       = f32[4 798 2 64]       \n",
      "split(v)                       = f32[4 798 2 64]       \n",
      "(attn_logits)                  = f32[4 2 798 798]      \n",
      "(attn_weights)                 = f32[4 2 798 798]      \n",
      "(attn)                         = f32[4 798 2 64]       \n",
      "merge(attn_vec)                = f32[4 798 128]        \n",
      "out_proj(out)                  = f32[4 798 128]        \n",
      "Inside MLPBlock\n",
      " ....  ....  ....  .... \n",
      "gelu-dense(x)                  = f32[4 798 512]        \n",
      "dense(x)                       = f32[4 798 128]        \n",
      "--------------------------------------------------------------------------------\n",
      "Inside SelfAttention\n",
      " ....  ....  ....  .... \n",
      "inputs(x)                      = f32[4 798 128]        \n",
      "linear(x)                      = f32[4 798 384]        \n",
      "split(q)                       = f32[4 798 2 64]       \n",
      "split(k)                       = f32[4 798 2 64]       \n",
      "split(v)                       = f32[4 798 2 64]       \n",
      "(attn_logits)                  = f32[4 2 798 798]      \n",
      "(attn_weights)                 = f32[4 2 798 798]      \n",
      "(attn)                         = f32[4 798 2 64]       \n",
      "merge(attn_vec)                = f32[4 798 128]        \n",
      "out_proj(out)                  = f32[4 798 128]        \n",
      "Inside MLPBlock\n",
      " ....  ....  ....  .... \n",
      "gelu-dense(x)                  = f32[4 798 512]        \n",
      "dense(x)                       = f32[4 798 128]        \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "rn_f(x)                        = f32[4 798 128]        \n",
      "n_out_slice(x)                 = f32[4 308 128]        \n",
      "(y_pred)                       = f32[4 308]            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">num_params = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.600</span> M\n",
       "</pre>\n"
      ],
      "text/plain": [
       "num_params = \u001b[1;36m0.600\u001b[0m M\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip Grads: 1.0\n",
      "Optimizer: adamw\n",
      "Optimizer kwargs: {'weight_decay': 0.05}\n",
      "Optimizer addons: {'clip_grads': 1.0, 'grad_acc_steps': None, 'adaptive_grad_clip': None}\n"
     ]
    }
   ],
   "source": [
    "fns = build_partial_functions(config)\n",
    "init_rng = jax.random.PRNGKey(config.random_seed)\n",
    "cur_state = fns[\"restore_state_from_checkpoint\"](init_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = config.denorm_arr_path\n",
    "# x_denorm_mean = np.load(os.path.join(p, \"x_denorm_mean.npy\"))\n",
    "# x_denorm_std = np.load(os.path.join(p, \"x_denorm_std.npy\"))\n",
    "# y_denorm_mean = np.load(os.path.join(p, \"y_denorm_mean.npy\"))\n",
    "# y_denorm_std = np.load(os.path.join(p, \"y_denorm_std.npy\"))\n",
    "# scale_output_weights = np.load(os.path.join(p, \"scale_output_weights.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from climsim_low_res_train.climsim_low_res_train_dataset_builder import (\n",
    "#     ABLATED_COL_NAMES,\n",
    "# )\n",
    "\n",
    "# sub_df = pd.read_csv(config.data_dir + \"/sample_submission.csv\", nrows=1)\n",
    "# sub_df.drop(columns=[\"sample_id\"], inplace=True)\n",
    "# sub_row = sub_df.iloc[0].values.astype(np.float32)\n",
    "\n",
    "# # Find out index of the ablated columns\n",
    "# not_ablated_col_indices = [\n",
    "#     sub_df.columns.tolist().index(col)\n",
    "#     for col in sub_df.columns.tolist()\n",
    "#     if col not in ABLATED_COL_NAMES and col != \"sample_id\"\n",
    "# ]\n",
    "\n",
    "# len(not_ablated_col_indices)\n",
    "\n",
    "# np.save(\"not_ablated_col_indices.npy\", not_ablated_col_indices)\n",
    "# t = np.load(\"not_ablated_col_indices.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Dummy Data\n",
      "\n",
      "ClimSimulator\n",
      "-------------------------\n",
      "inputs(x)                      = f32[4 490]            \n",
      "expand_dims(x)                 = f32[4 490 1]          \n",
      "concat_x_learn(x)              = f32[4 490 128]        \n",
      "concat_y_learn(x)              = f32[4 798 128]        \n",
      "pos_emb(x)                     = f32[4 798 128]        \n",
      "Inside SelfAttention\n",
      " ....  ....  ....  .... \n",
      "inputs(x)                      = f32[4 798 128]        \n",
      "linear(x)                      = f32[4 798 384]        \n",
      "split(q)                       = f32[4 798 2 64]       \n",
      "split(k)                       = f32[4 798 2 64]       \n",
      "split(v)                       = f32[4 798 2 64]       \n",
      "(attn_logits)                  = f32[4 2 798 798]      \n",
      "(attn_weights)                 = f32[4 2 798 798]      \n",
      "(attn)                         = f32[4 798 2 64]       \n",
      "merge(attn_vec)                = f32[4 798 128]        \n",
      "out_proj(out)                  = f32[4 798 128]        \n",
      "Inside MLPBlock\n",
      " ....  ....  ....  .... \n",
      "gelu-dense(x)                  = f32[4 798 512]        \n",
      "dense(x)                       = f32[4 798 128]        \n",
      "--------------------------------------------------------------------------------\n",
      "Inside SelfAttention\n",
      " ....  ....  ....  .... \n",
      "inputs(x)                      = f32[4 798 128]        \n",
      "linear(x)                      = f32[4 798 384]        \n",
      "split(q)                       = f32[4 798 2 64]       \n",
      "split(k)                       = f32[4 798 2 64]       \n",
      "split(v)                       = f32[4 798 2 64]       \n",
      "(attn_logits)                  = f32[4 2 798 798]      \n",
      "(attn_weights)                 = f32[4 2 798 798]      \n",
      "(attn)                         = f32[4 798 2 64]       \n",
      "merge(attn_vec)                = f32[4 798 128]        \n",
      "out_proj(out)                  = f32[4 798 128]        \n",
      "Inside MLPBlock\n",
      " ....  ....  ....  .... \n",
      "gelu-dense(x)                  = f32[4 798 512]        \n",
      "dense(x)                       = f32[4 798 128]        \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "rn_f(x)                        = f32[4 798 128]        \n",
      "n_out_slice(x)                 = f32[4 308 128]        \n",
      "(y_pred)                       = f32[4 308]            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array(-0.8052857, dtype=float32),\n",
       " Array(-0.80362886, dtype=float32),\n",
       " Array(0.13759618, dtype=float32),\n",
       " Array(-0.94311, dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = fns[\"build_input\"]()\n",
    "\n",
    "inputs = next(train_data)\n",
    "\n",
    "net = fns[\"net\"]\n",
    "train_state = cur_state[\"train_state\"]\n",
    "\n",
    "net_apply = jax.pmap(\n",
    "    lambda *a: net.apply(*a, is_training=False),\n",
    "    axis_name=\"i\",\n",
    ")\n",
    "\n",
    "y_pred, _ = net_apply(\n",
    "    train_state.ema_params,\n",
    "    train_state.ema_state,\n",
    "    None,\n",
    "    inputs,\n",
    ")\n",
    "\n",
    "y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "y_true = inputs[\"targets\"].reshape(-1, y_pred.shape[-1])\n",
    "\n",
    "dnorm_fns = utils.denorm_and_scale_wrapper(config.denorm_arr_path)\n",
    "dnorm = dnorm_fns[\"denorm_output\"]\n",
    "dnorm_scale = dnorm_fns[\"denorm_and_scale_output\"]\n",
    "dnorm_scale_and_expand = dnorm_fns[\"denorm_scale_and_expand_output\"]\n",
    "\n",
    "y_pred_dnorm = dnorm(y_pred)\n",
    "y_true_dnorm = dnorm(inputs[\"targets\"].reshape(-1, y_pred.shape[-1]))\n",
    "\n",
    "y_pred_old = dnorm_scale(y_pred)\n",
    "y_true_old = dnorm_scale(y_true)\n",
    "\n",
    "y_pred_new = dnorm_scale_and_expand(y_pred)\n",
    "y_true_new = dnorm_scale_and_expand(y_true)\n",
    "\n",
    "r2_score_dnorm = calc_r2_score(y_true_dnorm, y_pred_dnorm)\n",
    "r2_score_dnorm = jnp.mean(r2_score_dnorm)\n",
    "\n",
    "r2_score_old = calc_r2_score(y_true_old, y_pred_old)\n",
    "r2_score_old = jnp.mean(r2_score_old)\n",
    "\n",
    "r2_score_new = calc_r2_score(y_true_new, y_pred_new)\n",
    "r2_score_new = jnp.mean(r2_score_new)\n",
    "\n",
    "direct_r2 = calc_r2_score(y_true, y_pred)\n",
    "direct_r2 = jnp.mean(direct_r2)\n",
    "\n",
    "r2_score_old, r2_score_new, r2_score_dnorm, direct_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-1.140182697697374,\n",
       "  -0.998114757917345,\n",
       "  -0.6102162701829839,\n",
       "  -1.0239268103195993],\n",
       " -0.9431101340293255)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score as sk_r2\n",
    "\n",
    "b_r2 = []\n",
    "for b in range(y_pred.shape[0]):\n",
    "    r2 = sk_r2(y_true[b], y_pred[b])\n",
    "    b_r2.append(r2)\n",
    "\n",
    "b_r2, np.mean(b_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-1.1401825 , -0.9981147 , -0.61021614, -1.0239267 ], dtype=float32),\n",
       " Array(-0.94311, dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jax.vmap\n",
    "def my_r2(y_true, y_pred):\n",
    "    numerator = jnp.sum((y_true - y_pred) ** 2)\n",
    "    denominator = jnp.sum((y_true - jnp.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (numerator / (denominator + 1e-7))\n",
    "    return r2\n",
    "\n",
    "b_r2 = my_r2(y_true, y_pred)\n",
    "b_r2, jnp.mean(b_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-0.7557789, -1.0223663, -1.0403209, -0.99517  ], dtype=float32),\n",
       " Array(-0.95340896, dtype=float32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v_my_r2 = jax.vmap(my_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_placeholder(y: Array):\n",
    "    B = y.shape[0]\n",
    "    placeholder = jnp.zeros((B, 368))\n",
    "    placeholder = placeholder.at[:, t].set(\n",
    "        y, indices_are_sorted=True, unique_indices=True\n",
    "    )\n",
    "    return placeholder\n",
    "\n",
    "y_pred, y_true = apply_placeholder(y_pred), apply_placeholder(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 368), (4, 368))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-0.9507216, dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = calc_r2_score(y_true, y_pred)\n",
    "r2_score = jnp.mean(r2_score)\n",
    "\n",
    "r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
